{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <div style=\"background-color: rgb(230, 230, 230);\">\n",
    "\n",
    "---\n",
    "# T501-SP24 - Lab Assignment 2\n",
    "# *Using Spark SQL to Analyze Flight On-Time Data*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgb(230, 230, 230);\">\n",
    "\n",
    "---\n",
    "## Assignment Details\n",
    "\n",
    "### Objectives\n",
    "The learning objectives of this assignment are to:\n",
    "1.\tPractice using Spark SQL to query, aggregate, and analyze structured data\n",
    "2.  Use Spark skills to answer open-ended analysis questions.\n",
    "2.  Work successfully in a team on a collaborative assignment\n",
    "\n",
    "### General Instructions\n",
    "* **Please attempt to do the majority of this assignment with Spark SQL.**  You may, however, find it necessary to mix in commands from the Spark DataFrame API. This is okay.\n",
    "* Upload the data files accompanying this notebook (**NovOntime.csv**, **Airports.csv**) into your user directory on Ambari in CloudXLab.  \n",
    "* Upload this Jupyter notebook to your Jupyter directory on CloudXLab. Enter all of your code into this notebook. \n",
    "* Your modified Jupyter notebook will serve as your groupâ€™s submission for the assignment. You should **also submit a PDF version** of the notebook (through \"print\" to a PDF or your system, or download as PDF from CloudXLab.)\n",
    "\n",
    "### Questions to Answer\n",
    "This assignment contains three types of tasks:\n",
    "1. Data reading, discovery, and output tasks\n",
    "2. Specific, closed-ended queries\n",
    "3. Open-ended analysis questions, usually requiring multiple queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1 - Data Reading and Discovery Tasks (4 x 5 pts each = 20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.0 - Set up Spark environment\n",
    "Execute (run) the code in the following cell to initiate the Spark environment and load required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// This command is necessary for loading the aggregation functions...\n",
    "import org.apache.spark.sql.functions._  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 - Read Data (5 pts)\n",
    "For each dataset:\n",
    "1. Read the .csv file into a Spark dataFrame\n",
    "1. Then display the first few rows of data.\n",
    "1. Next, output the number of rows of data in the dataFrame.\n",
    "1. Finally, create a Spark SQL view from the dataFrame. \n",
    "\n",
    "The code to read the airports file has been provided for you; perform a similar set of commands for the OnTime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|       CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|  Allentown|   PA|    USA|40.65236|  -75.4404|\n",
      "|      ABI|Abilene Regional ...|    Abilene|   TX|    USA|32.41132|  -99.6819|\n",
      "|      ABQ|Albuquerque Inter...|Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|   Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|     Albany|   GA|    USA|31.53552| -84.19447|\n",
      "+---------+--------------------+-----------+-----+-------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- AIRPORT: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n",
      "Number of rows: 322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "directory = HW 2/\n",
       "csvFile = HW 2/Airports.csv\n",
       "airportDF = [IATA_CODE: string, AIRPORT: string ... 5 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[IATA_CODE: string, AIRPORT: string ... 5 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Path to data set (in HDFS (Ambari))\n",
    "val directory = \"HW 2/\" // change this path to fit your setup\n",
    "val csvFile = directory + \"Airports.csv\"\n",
    "\n",
    "// Read and create a temporary view\n",
    "val airportDF = spark.read.format(\"csv\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(csvFile)\n",
    "// verify\n",
    "airportDF.show(5)\n",
    "airportDF.printSchema()\n",
    "println(\"Number of rows: \" + airportDF.count())\n",
    "\n",
    "// Create a temporary view\n",
    "airportDF.createOrReplaceTempView(\"airportView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 - Check Databases, Tables, and Table Structure (0 pts)\n",
    "This code is provided for you. Be sure to update the name of the temp_view as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|   name|     description|         locationUri|\n",
      "+-------+----------------+--------------------+\n",
      "|default|default database|/apps/hive/warehouse|\n",
      "+-------+----------------+--------------------+\n",
      "\n",
      "+-----------+--------+-----------+---------+-----------+\n",
      "|       name|database|description|tableType|isTemporary|\n",
      "+-----------+--------+-----------+---------+-----------+\n",
      "|airportview|    null|       null|TEMPORARY|       true|\n",
      "+-----------+--------+-----------+---------+-----------+\n",
      "\n",
      "+---------+-----------+--------+--------+-----------+--------+\n",
      "|     name|description|dataType|nullable|isPartition|isBucket|\n",
      "+---------+-----------+--------+--------+-----------+--------+\n",
      "|IATA_CODE|       null|  string|    true|      false|   false|\n",
      "|  AIRPORT|       null|  string|    true|      false|   false|\n",
      "|     CITY|       null|  string|    true|      false|   false|\n",
      "|    STATE|       null|  string|    true|      false|   false|\n",
      "|  COUNTRY|       null|  string|    true|      false|   false|\n",
      "| LATITUDE|       null|  double|    true|      false|   false|\n",
      "|LONGITUDE|       null|  double|    true|      false|   false|\n",
      "+---------+-----------+--------+--------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Check the databases, tables, and table contents\n",
    "spark.catalog.listDatabases().show() // databases\n",
    "spark.catalog.listTables().show() // tables & views\n",
    "spark.catalog.listColumns(\"airportView\").show() // table columns \n",
    "// do the same for the SQL View containing the NovOntime information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 - Verify Dates in File (5 pts)\n",
    "From the file name, we might guess (correctly) that the file contains on-time information from the month of November. But for how much of the month, and for what year(s)? \n",
    "\n",
    "Write queries to determine the range of values for the Year, Month, Day of Month, and Day of Week contained in the dataset. (Hint: since these values are all numeric, think MIN() and MAX() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 2) / 2]+----------+----+-------+-----+----------+---------+-------+------+----+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+\n",
      "|IDENTIFIER|Year|Quarter|Month|DayofMonth|DayOfWeek|Carrier|Origin|Dest|CRSDepTime|DepTime|DepDelay|DepDelayMinutes|DepDel15|DepartureDelayGroups|DepTimeBlk|TaxiOut|WheelsOff|WheelsOn|TaxiIn|CRSArrTime|ArrTime|ArrDelay|ArrDelayMinutes|ArrDel15|ArrivalDelayGroups|ArrTimeBlk|Cancelled|CancellationCode|Diverted|CRSElapsedTime|ActualElapsedTime|AirTime|Distance|DistanceGroup|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----------+----+-------+-----+----------+---------+-------+------+----+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+\n",
      "|         1|2010|      4|   11|         1|        1|     AA|   JFK| LAX|       900|    913|      13|             13|       0|                   0| 0900-0959|     17|      930|    1148|    18|      1215|   1206|      -9|              0|       0|                -1| 1200-1259|        0|            null|       0|           375|              353|    318|    2475|           10|          NA|          NA|      NA|           NA|               NA|\n",
      "|         2|2010|      4|   11|         2|        2|     AA|   JFK| LAX|       900|    856|      -4|              0|       0|                  -1| 0900-0959|     13|      909|    1105|    10|      1215|   1115|     -60|              0|       0|                -2| 1200-1259|        0|            null|       0|           375|              319|    296|    2475|           10|          NA|          NA|      NA|           NA|               NA|\n",
      "|         3|2010|      4|   11|         3|        3|     AA|   JFK| LAX|       900|    901|       1|              1|       0|                   0| 0900-0959|     20|      921|    1132|     8|      1215|   1140|     -35|              0|       0|                -2| 1200-1259|        0|            null|       0|           375|              339|    311|    2475|           10|          NA|          NA|      NA|           NA|               NA|\n",
      "|         4|2010|      4|   11|         4|        4|     AA|   JFK| LAX|       900|    905|       5|              5|       0|                   0| 0900-0959|     25|      930|    1159|    16|      1215|   1215|       0|              0|       0|                 0| 1200-1259|        0|            null|       0|           375|              370|    329|    2475|           10|          NA|          NA|      NA|           NA|               NA|\n",
      "|         5|2010|      4|   11|         5|        5|     AA|   JFK| LAX|       900|    900|       0|              0|       0|                   0| 0900-0959|     23|      923|    1128|     8|      1215|   1136|     -39|              0|       0|                -2| 1200-1259|        0|            null|       0|           375|              336|    305|    2475|           10|          NA|          NA|      NA|           NA|               NA|\n",
      "+----------+----+-------+-----+----------+---------+-------+------+----+----------+-------+--------+---------------+--------+--------------------+----------+-------+---------+--------+------+----------+-------+--------+---------------+--------+------------------+----------+---------+----------------+--------+--------------+-----------------+-------+--------+-------------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- IDENTIFIER: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Carrier: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- DepDelayMinutes: string (nullable = true)\n",
      " |-- DepDel15: string (nullable = true)\n",
      " |-- DepartureDelayGroups: string (nullable = true)\n",
      " |-- DepTimeBlk: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- WheelsOff: string (nullable = true)\n",
      " |-- WheelsOn: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- ArrDelayMinutes: string (nullable = true)\n",
      " |-- ArrDel15: string (nullable = true)\n",
      " |-- ArrivalDelayGroups: string (nullable = true)\n",
      " |-- ArrTimeBlk: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- DistanceGroup: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "novOntimeFile = HW 2/NovOntime.csv\n",
       "novOntimeDF = [IDENTIFIER: int, Year: int ... 38 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[IDENTIFIER: int, Year: int ... 38 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val novOntimeFile = directory + \"NovOntime.csv\"\n",
    "\n",
    "// Read and create a temporary view\n",
    "val novOntimeDF = spark.read.format(\"csv\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(novOntimeFile)\n",
    "\n",
    "// Verify the DataFrame\n",
    "novOntimeDF.show(5)\n",
    "novOntimeDF.printSchema()\n",
    "\n",
    "// Create a temporary view\n",
    "novOntimeDF.createOrReplaceTempView(\"novOntimeView\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------+--------------+--------------+-------------+-------------+\n",
      "|Min_Year|Max_Year|Min_Month|Max_Month|Min_DayOfMonth|Max_DayOfMonth|Min_DayOfWeek|Max_DayOfWeek|\n",
      "+--------+--------+---------+---------+--------------+--------------+-------------+-------------+\n",
      "|    2010|    2010|       11|       11|             1|            30|            1|            7|\n",
      "+--------+--------+---------+---------+--------------+--------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// find the range of Year, Month, Day of Month, and Day of Week\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    MIN(Year) AS Min_Year, MAX(Year) AS Max_Year, \n",
    "    MIN(Month) AS Min_Month, MAX(Month) AS Max_Month, \n",
    "    MIN(DayofMonth) AS Min_DayOfMonth, MAX(DayofMonth) AS Max_DayOfMonth, \n",
    "    MIN(DayOfWeek) AS Min_DayOfWeek, MAX(DayOfWeek) AS Max_DayOfWeek \n",
    "FROM novOntimeView\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4  - Understand the Data (5 pts)\n",
    "To get a better sense of the breadth and details of the data, query the database to discover the following basic facts:\n",
    "* Number and names of ArrTimeBlks\n",
    "* Number and names of Dest(intation) airports\n",
    "* Number and names of Origin airports\n",
    "* Number and names of Carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 13:=================================================>    (182 + 8) / 200]+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|NumberOfArrTimeBlks|NamesOfArrTimeBlks                                                                                                                                                                                               |\n",
      "+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|19                 |[1300-1359, 1400-1459, 1100-1159, 2100-2159, 2000-2059, 0001-0559, 2200-2259, 0600-0659, 0900-0959, 1800-1859, 1700-1759, 2300-2359, 0700-0759, 1200-1259, 1000-1059, 0800-0859, 1900-1959, 1600-1659, 1500-1559]|\n",
      "+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Number and Names of ArrTimeBlks\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT ArrTimeBlk) AS NumberOfArrTimeBlks, \n",
    "    COLLECT_LIST(DISTINCT ArrTimeBlk) AS NamesOfArrTimeBlks\n",
    "FROM novOntimeView\n",
    "\"\"\").show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|NumberOfDestAirports|NamesOfDestAirports                                                                                                                                                                                                                                                                                         |\n",
      "+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|60                  |[LGA, IAD, PHX, MSP, CLT, SAT, PIT, ABQ, BUF, RDU, PDX, BUR, MCI, LAX, MSY, SNA, CMH, SJC, DCA, MCO, SAN, LAS, MDW, ANC, RSW, PBI, ORD, JAX, BOS, MKE, DTW, STL, DEN, FLL, CVG, OGG, AUS, BNA, PHL, TPA, HOU, DAL, BWI, IAH, SFO, CLE, EWR, HNL, SMF, OMA, BDL, SLC, SEA, OAK, MIA, DFW, JFK, SJU, IND, ATL]|\n",
      "+--------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Number and Names of Destination Airports (Dest)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT Dest) AS NumberOfDestAirports, \n",
    "    COLLECT_LIST(DISTINCT Dest) AS NamesOfDestAirports\n",
    "FROM novOntimeView\n",
    "\"\"\").show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|NumberOfOriginAirports|NamesOfOriginAirports                                                                                                                                                                                                                                                                                       |\n",
      "+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|60                    |[LGA, IAD, PHX, MSP, CLT, SAT, PIT, ABQ, BUF, RDU, PDX, BUR, MCI, LAX, MSY, SNA, CMH, SJC, DCA, MCO, SAN, LAS, MDW, ANC, RSW, PBI, ORD, JAX, BOS, MKE, DTW, DEN, STL, FLL, CVG, OGG, AUS, BNA, PHL, TPA, HOU, DAL, BWI, IAH, SFO, CLE, EWR, HNL, SMF, OMA, BDL, SLC, SEA, OAK, MIA, DFW, JFK, SJU, IND, ATL]|\n",
      "+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Number and Names of Origin Airports (Origin)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT Origin) AS NumberOfOriginAirports, \n",
    "    COLLECT_LIST(DISTINCT Origin) AS NamesOfOriginAirports\n",
    "FROM novOntimeView\n",
    "\"\"\").show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================================================> (196 + 4) / 200]+----------------+------------------------+\n",
      "|NumberOfCarriers|NamesOfCarriers         |\n",
      "+----------------+------------------------+\n",
      "|6               |[AS, UA, WN, AA, B6, DL]|\n",
      "+----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Number and Names of Carriers\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT Carrier) AS NumberOfCarriers, \n",
    "    COLLECT_LIST(DISTINCT Carrier) AS NamesOfCarriers\n",
    "FROM novOntimeView\n",
    "\"\"\").show(false)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.5 - Write and Compare Parquet File (5 pts)\n",
    "Write a command to output the file NovOntime.csv into Parquet format. List the sizes of the two files and compute the disk space savings of the parquet version. (Hint 1: consider using the coalesce(1) function to force the data into one file instead of multiple parts. Hint 2: to determine the file sizes, simply go to the Ambari HDFS (Files) interface and refer to the size column.)\n",
    "\n",
    "* Size of CSV file:\n",
    "* Size of Parquet file:\n",
    "* % Savings of Parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    }
   ],
   "source": [
    "//Write DataFrame to Parquet\n",
    "\n",
    "novOntimeDF.coalesce(1).write.mode(\"overwrite\").parquet(directory + \"NovOntime.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.18181818181819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sizeOfCsvFile = 27.5\n",
       "sizeOfParquetFile = 4.9\n",
       "savings = 0.8218181818181819\n",
       "percentageSavings = 82.18181818181819\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "82.18181818181819"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Check File Sizes and Compute Savings\n",
    "//Size of CSV file: 27.5 MB\n",
    "//Size of Parquet file: 4.9 MB\n",
    "\n",
    "\n",
    "val sizeOfCsvFile: Double = 27.5 // MB\n",
    "val sizeOfParquetFile: Double = 4.9 // MB\n",
    "\n",
    "//calculate the savings percentage\n",
    "val savings: Double = (sizeOfCsvFile - sizeOfParquetFile) / sizeOfCsvFile\n",
    "val percentageSavings: Double = savings * 100\n",
    "\n",
    "println(percentageSavings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ---\n",
    "\n",
    "# Part 2 - Specific Queries (8 x 5 pts each = 40 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.1 - Mean Delay by Carrier and Day Of Week\n",
    "Find the mean arrival delay by carrier and day of week.\n",
    "    \n",
    "(Note the difference between ArrDelay and ArrDelayMinutes in the dataset.\n",
    "We want ArrDelayMinutes for this problem; this is the variable for which flights that arrived early have a delay of 0 rather than a negative value.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 25:=========>                                                (1 + 5) / 6]+-------+---------+------------------+\n",
      "|Carrier|DayOfWeek|  MeanArrivalDelay|\n",
      "+-------+---------+------------------+\n",
      "|     AA|        1| 9.240923076923076|\n",
      "|     AA|        2|10.456535141800247|\n",
      "|     AA|        3| 7.576290852833107|\n",
      "|     AA|        4|7.5224005001041885|\n",
      "|     AA|        5| 8.727971614429332|\n",
      "|     AA|        6| 5.508827908955541|\n",
      "|     AA|        7| 6.869996113486203|\n",
      "|     AS|        1|12.388972809667674|\n",
      "|     AS|        2| 9.362307692307692|\n",
      "|     AS|        3| 6.745746691871456|\n",
      "|     AS|        4|4.8410206084396465|\n",
      "|     AS|        5| 6.545101842870999|\n",
      "|     AS|        6| 7.022380467955239|\n",
      "|     AS|        7| 8.171905697445972|\n",
      "|     B6|        1|14.284249767008388|\n",
      "|     B6|        2|10.716543209876543|\n",
      "|     B6|        3| 9.995665634674923|\n",
      "|     B6|        4|13.315656565656566|\n",
      "|     B6|        5|10.866514546491729|\n",
      "|     B6|        6| 9.452365930599369|\n",
      "+-------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "meanDelayByCarrierAndDayOfWeek = [Carrier: string, DayOfWeek: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 1 more field]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "// find the mean arrival delay by carrier and day of week\n",
    "val meanDelayByCarrierAndDayOfWeek = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek, \n",
    "    AVG(ArrDelayMinutes) AS MeanArrivalDelay\n",
    "FROM novOntimeView\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "meanDelayByCarrierAndDayOfWeek.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.2 - Mean Delay by Destination and Day of Week\n",
    "Find mean arrival delay by airport and day of Week for selected airports.\n",
    "Include only the following airports: IND, ORD, STL, CVG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+\n",
      "|Airport|DayOfWeek|  MeanArrivalDelay|\n",
      "+-------+---------+------------------+\n",
      "|    CVG|        1|  8.16891891891892|\n",
      "|    CVG|        2|   8.9009009009009|\n",
      "|    CVG|        3|10.552631578947368|\n",
      "|    CVG|        4| 8.303571428571429|\n",
      "|    CVG|        5| 6.460869565217391|\n",
      "|    CVG|        6| 3.830188679245283|\n",
      "|    CVG|        7|         11.859375|\n",
      "|    IND|        1|   8.8659793814433|\n",
      "|    IND|        2| 8.431034482758621|\n",
      "|    IND|        3| 9.487179487179487|\n",
      "|    IND|        4| 7.948529411764706|\n",
      "|    IND|        5| 7.302013422818792|\n",
      "|    IND|        6| 9.242424242424242|\n",
      "|    IND|        7|              5.75|\n",
      "|    ORD|        1|12.939465875370919|\n",
      "|    ORD|        2| 5.386961722488039|\n",
      "|    ORD|        3| 7.837600585223116|\n",
      "|    ORD|        4| 4.538586515028432|\n",
      "|    ORD|        5| 4.046692607003891|\n",
      "|    ORD|        6|  4.31453744493392|\n",
      "+-------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "meanDelayByDestinationAndDayOfWeek = [Airport: string, DayOfWeek: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Airport: string, DayOfWeek: int ... 1 more field]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// find the mean arrival delay by destination airport and day of week for selected airports\n",
    "val meanDelayByDestinationAndDayOfWeek = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Dest AS Airport, \n",
    "    DayOfWeek, \n",
    "    AVG(ArrDelayMinutes) AS MeanArrivalDelay\n",
    "FROM novOntimeView\n",
    "WHERE Dest IN ('IND', 'ORD', 'STL', 'CVG')\n",
    "GROUP BY Dest, DayOfWeek\n",
    "ORDER BY Dest, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "meanDelayByDestinationAndDayOfWeek.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.3 - Mean Delay by Day, Time Block, and Destination\n",
    "Find the mean arrival delay by day of week, arrival time block, and destination.\n",
    "(Again use ArrDelayMinutes, not ArrDelay.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+------------------+                           \n",
      "|DayOfWeek|ArrTimeBlk|Destination|  MeanArrivalDelay|\n",
      "+---------+----------+-----------+------------------+\n",
      "|        1| 0001-0559|        ABQ|             135.0|\n",
      "|        1| 0001-0559|        ANC|25.565217391304348|\n",
      "|        1| 0001-0559|        ATL|               1.1|\n",
      "|        1| 0001-0559|        AUS|               2.0|\n",
      "|        1| 0001-0559|        BDL|              12.0|\n",
      "|        1| 0001-0559|        BNA|              15.0|\n",
      "|        1| 0001-0559|        BOS| 11.18421052631579|\n",
      "|        1| 0001-0559|        BUF|10.333333333333334|\n",
      "|        1| 0001-0559|        BWI| 7.933333333333334|\n",
      "|        1| 0001-0559|        CMH|               5.0|\n",
      "|        1| 0001-0559|        DCA|3.2857142857142856|\n",
      "|        1| 0001-0559|        DFW| 16.27027027027027|\n",
      "|        1| 0001-0559|        EWR|10.571428571428571|\n",
      "|        1| 0001-0559|        FLL| 9.944444444444445|\n",
      "|        1| 0001-0559|        HOU|27.818181818181817|\n",
      "|        1| 0001-0559|        IAD|6.1923076923076925|\n",
      "|        1| 0001-0559|        IAH|               6.0|\n",
      "|        1| 0001-0559|        IND|               7.5|\n",
      "|        1| 0001-0559|        JFK|              19.0|\n",
      "|        1| 0001-0559|        LAS|               0.0|\n",
      "+---------+----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "meanDelayByDayTimeBlockAndDestination = [DayOfWeek: int, ArrTimeBlk: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DayOfWeek: int, ArrTimeBlk: string ... 2 more fields]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// find the mean arrival delay by day of week, arrival time block, and destination\n",
    "val meanDelayByDayTimeBlockAndDestination = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    DayOfWeek, \n",
    "    ArrTimeBlk, \n",
    "    Dest AS Destination, \n",
    "    AVG(ArrDelayMinutes) AS MeanArrivalDelay\n",
    "FROM novOntimeView\n",
    "GROUP BY DayOfWeek, ArrTimeBlk, Dest\n",
    "ORDER BY DayOfWeek, ArrTimeBlk, Dest\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "meanDelayByDayTimeBlockAndDestination.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.4 - Cost of Delays per Carrier\n",
    "If a minute of delay costs an airline $78, how much, in millions, was lost to <u>carrier, weather, and late aircraft delays?</u> The result should be one total per carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 31:=========>                                                (1 + 5) / 6]+-------+-------------------+\n",
      "|Carrier|TotalCostInMillions|\n",
      "+-------+-------------------+\n",
      "|     WN|               39.2|\n",
      "|     DL|              20.23|\n",
      "|     AA|              14.51|\n",
      "|     B6|               7.07|\n",
      "|     UA|               5.44|\n",
      "|     AS|               2.57|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "costOfDelaysPerCarrier = [Carrier: string, TotalCostInMillions: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, TotalCostInMillions: double]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// calculate the cost of delays per carrier\n",
    "val costOfDelaysPerCarrier = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier,\n",
    "    ROUND(SUM((CarrierDelay + WeatherDelay + LateAircraftDelay) * 78) / 1000000, 2) AS TotalCostInMillions\n",
    "FROM novOntimeView\n",
    "GROUP BY Carrier\n",
    "ORDER BY TotalCostInMillions DESC\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "costOfDelaysPerCarrier.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.5 - Delays from Indianapolis for American and Delta\n",
    "We want to compare departure delays from the Indianapolis airport (IND) for carriers American Airlines (AA) and Delta Airlines (DL). Group the results by Carrier and DayOfWeek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------------+\n",
      "|Carrier|DayOfWeek|AverageDepartureDelay|\n",
      "+-------+---------+---------------------+\n",
      "|     AA|        1|                  0.6|\n",
      "|     AA|        2|                 7.24|\n",
      "|     AA|        3|                  1.4|\n",
      "|     AA|        4|    4.388888888888889|\n",
      "|     AA|        5|   12.421052631578947|\n",
      "|     AA|        6|   1.6666666666666667|\n",
      "|     AA|        7|                 5.55|\n",
      "|     DL|        1|    5.538461538461538|\n",
      "|     DL|        2|             5.765625|\n",
      "|     DL|        3|    13.78688524590164|\n",
      "|     DL|        4|    6.627118644067797|\n",
      "|     DL|        5|                 7.55|\n",
      "|     DL|        6|    5.084745762711864|\n",
      "|     DL|        7|   14.044117647058824|\n",
      "+-------+---------+---------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "delaysFromIndianapolis = [Carrier: string, DayOfWeek: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 1 more field]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// compare departure delays for American Airlines (AA) and Delta Airlines (DL) from Indianapolis (IND)\n",
    "val delaysFromIndianapolis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek, \n",
    "    AVG(DepDelayMinutes) AS AverageDepartureDelay\n",
    "FROM novOntimeView\n",
    "WHERE \n",
    "    Origin = 'IND' AND \n",
    "    Carrier IN ('AA', 'DL')\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "delaysFromIndianapolis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.6 - Delays for American and United at Select Destinations\n",
    "We'd like to <u>compare American Airlines and United Airlines with flights leaving from St. Louis, Dallas FortWorth, Indianapolis, and JFK.</u> We want to <u>use the average ArriveDelay in minutes</u> as the metric to compare these carriers. We'd like to have an output organized by DayOfWeek followed by Carrier, each showing the average ArrDelayMinutes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------------------+\n",
      "|DayOfWeek|Carrier|AverageArrivalDelay|\n",
      "+---------+-------+-------------------+\n",
      "|        1|     AA|  7.089622641509434|\n",
      "|        1|     UA| 2.7966101694915255|\n",
      "|        2|     AA|  13.19537517697027|\n",
      "|        2|     UA|  4.254237288135593|\n",
      "|        3|     AA|  7.599645180366647|\n",
      "|        3|     UA|  2.351063829787234|\n",
      "|        4|     AA|  7.528883183568678|\n",
      "|        4|     UA|  1.632183908045977|\n",
      "|        5|     AA| 10.761356753482739|\n",
      "|        5|     UA|  2.797752808988764|\n",
      "|        6|     AA|  5.579268292682927|\n",
      "|        6|     UA| 4.8933333333333335|\n",
      "|        7|     AA|  6.166965888689408|\n",
      "|        7|     UA|  4.586206896551724|\n",
      "+---------+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "delaysForAmericanAndUnited = [DayOfWeek: int, Carrier: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DayOfWeek: int, Carrier: string ... 1 more field]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// compare average arrival delay for American Airlines (AA) and United Airlines (UA)\n",
    "val delaysForAmericanAndUnited = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    DayOfWeek, \n",
    "    Carrier, \n",
    "    AVG(ArrDelayMinutes) AS AverageArrivalDelay\n",
    "FROM novOntimeView\n",
    "WHERE \n",
    "    Origin IN ('STL', 'DFW', 'IND', 'JFK') AND \n",
    "    Carrier IN ('AA', 'UA')\n",
    "GROUP BY DayOfWeek, Carrier\n",
    "ORDER BY DayOfWeek, Carrier\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "delaysForAmericanAndUnited.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.7 - Regional airports by State\n",
    "We would like to determine the airports located in Indiana and the surrounding states. Find all of the airports listed in the Airports.csv file that are located in the states of Indiana, Illinois, Kentucky, Ohio, and Michigan. Sort the results by State and City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|                Name|            CITY|STATE|\n",
      "+--------------------+----------------+-----+\n",
      "|Central Illinois ...|     Bloomington|   IL|\n",
      "|University of Ill...|Champaign/Urbana|   IL|\n",
      "|Chicago Midway In...|         Chicago|   IL|\n",
      "|Chicago O'Hare In...|         Chicago|   IL|\n",
      "|Quad City Interna...|          Moline|   IL|\n",
      "|General Wayne A. ...|          Peoria|   IL|\n",
      "|Abraham Lincoln C...|     Springfield|   IL|\n",
      "|Evansville Region...|      Evansville|   IN|\n",
      "|Fort Wayne Intern...|      Fort Wayne|   IN|\n",
      "|Indianapolis Inte...|    Indianapolis|   IN|\n",
      "|South Bend Intern...|      South Bend|   IN|\n",
      "|Cincinnati/Northe...|       Covington|   KY|\n",
      "|  Blue Grass Airport|       Lexington|   KY|\n",
      "|Louisville Intern...|      Louisville|   KY|\n",
      "|Barkley Regional ...|         Paducah|   KY|\n",
      "|Alpena County Reg...|          Alpena|   MI|\n",
      "|Detroit Metropoli...|         Detroit|   MI|\n",
      "|Delta County Airport|        Escanaba|   MI|\n",
      "|Bishop Internatio...|           Flint|   MI|\n",
      "|Gerald R. Ford In...|    Grand Rapids|   MI|\n",
      "+--------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "airportsByStateCorrected = [Name: string, CITY: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, CITY: string ... 1 more field]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// find airports in Indiana and surrounding states\n",
    "val airportsByStateCorrected = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    AIRPORT AS Name, \n",
    "    CITY, \n",
    "    STATE\n",
    "FROM airportView\n",
    "WHERE \n",
    "    STATE IN ('IN', 'IL', 'KY', 'OH', 'MI')\n",
    "ORDER BY STATE, CITY\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "airportsByStateCorrected.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 2.8 - Airports with direct connections to Indianapolis\n",
    "Print out the City, State, and Airport name of all airports that have a direct connection with Indianapolis. (Yes, this will require a JOIN.) Be sure to list each airport only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+                                  \n",
      "|             CITY|STATE|                Name|\n",
      "+-----------------+-----+--------------------+\n",
      "|          Phoenix|   AZ|Phoenix Sky Harbo...|\n",
      "|      Los Angeles|   CA|Los Angeles Inter...|\n",
      "|           Denver|   CO|Denver Internatio...|\n",
      "|          Orlando|   FL|Orlando Internati...|\n",
      "|            Tampa|   FL|Tampa Internation...|\n",
      "|          Atlanta|   GA|Hartsfield-Jackso...|\n",
      "|          Chicago|   IL|Chicago Midway In...|\n",
      "|     Indianapolis|   IN|Indianapolis Inte...|\n",
      "|        Baltimore|   MD|Baltimore-Washing...|\n",
      "|          Detroit|   MI|Detroit Metropoli...|\n",
      "|      Minneapolis|   MN|Minneapolis-Saint...|\n",
      "|      Kansas City|   MO|Kansas City Inter...|\n",
      "|        Las Vegas|   NV|McCarran Internat...|\n",
      "|Dallas-Fort Worth|   TX|Dallas/Fort Worth...|\n",
      "|   Salt Lake City|   UT|Salt Lake City In...|\n",
      "+-----------------+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "directConnectionsToIndianapolis = [CITY: string, STATE: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[CITY: string, STATE: string ... 1 more field]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// find airports with direct connections to Indianapolis\n",
    "val directConnectionsToIndianapolis = spark.sql(\"\"\"\n",
    "SELECT DISTINCT \n",
    "    a.CITY, \n",
    "    a.STATE, \n",
    "    a.AIRPORT AS Name\n",
    "FROM \n",
    "    novOntimeView f\n",
    "JOIN \n",
    "    airportView a\n",
    "ON \n",
    "    f.Dest = a.IATA_CODE OR f.Origin = a.IATA_CODE\n",
    "WHERE \n",
    "    f.Origin = 'IND' OR f.Dest = 'IND'\n",
    "AND \n",
    "    a.IATA_CODE != 'IND'\n",
    "ORDER BY \n",
    "    a.STATE, a.CITY\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "directConnectionsToIndianapolis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3 - Open-Ended Analyses (2 x 10 pts ea = 20 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 3.1 - \"Making up time\" Policy Analysis\n",
    "Is there a way the data might tell us <u>which airlines have a strict policy against \"making time up in the air\"?</u> When there is a Departure delay, you will often hear pilots announce that they are going to \"make up time in the air\" (fly faster) to get back on schedule.  Some airlines do not like this, because it raises fuel costs.  See if you can tell which airlines discourage this. Explain your analysis and rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|Carrier|      AvgTimeMadeUp|\n",
      "+-------+-------------------+\n",
      "|     UA|  6.340970873786408|\n",
      "|     WN|  4.357851450874707|\n",
      "|     B6| 2.6141316310807836|\n",
      "|     AA| 2.4502923976608186|\n",
      "|     DL| 1.3168550992155053|\n",
      "|     AS|0.31100478468899523|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeMakingPolicyAnalysis = [Carrier: string, AvgTimeMadeUp: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, AvgTimeMadeUp: double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Analyze: \"making up time in the air\" policy by airlines\n",
    "val timeMakingPolicyAnalysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    AVG(DepDelayMinutes - ArrDelayMinutes) AS AvgTimeMadeUp\n",
    "FROM novOntimeView\n",
    "WHERE DepDelayMinutes > 0\n",
    "GROUP BY Carrier\n",
    "ORDER BY AvgTimeMadeUp DESC\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "timeMakingPolicyAnalysis.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It appears that AS may have a strict policy against \"making time up in the air\" with an average time made up (ATM) of .311. It is also possible that other airlines such as DL (ATM 1.31) may discourgae it as well within a threshold, however it probably is not a strict policy against \"making time up in the air\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task 3.2 - Sunday & Monday Delay Analysis\n",
    "\n",
    "Weâ€™d like you to <u>analyze flights that arrived late, specifically examining Sunday and Monday performance for each carrier.</u>  What patterns do you see?  What factors might influence the numbers or analysis?\n",
    "(For example, if you were to sum the delayed minutes for each carrier, it seems alarming that carrier WN has, by far, the highest total delays.  Do you see any reasons for this?)  Again, focus your analysis on Sunday and Monday flights delayed on arrival at their destination airport, and see what you can analyze to explain what may be happening with these carriers on these particular days. Again, explain your analyses and rationale.\n",
    "\n",
    "(Hint: Nov 1, 2010 was a Monday.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+--------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Carrier|DayOfWeek|NumberOfFlights|ARRDelay|DEPDelay|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|     AA|        1|           2331| 60066.0| 51897.0|     19952.0|      1504.0| 16632.0|          0.0|          13627.0|\n",
      "|     AA|        7|           1485| 35353.0| 34339.0|     12300.0|       300.0|  8745.0|         12.0|           8771.0|\n",
      "|     AS|        1|            521| 16403.0| 11613.0|      2478.0|      2137.0|  6405.0|          0.0|           3749.0|\n",
      "|     AS|        7|            344|  8319.0|  6092.0|      1943.0|        12.0|  2656.0|          0.0|           2415.0|\n",
      "|     B6|        1|            998| 30654.0| 27672.0|     10948.0|         0.0|  7632.0|         50.0|           9100.0|\n",
      "|     B6|        7|            653| 19107.0| 17650.0|      7571.0|         8.0|  3494.0|         64.0|           5917.0|\n",
      "|     DL|        1|           3862|106103.0| 90155.0|     28950.0|      1341.0| 28501.0|          0.0|          35058.0|\n",
      "|     DL|        7|           2774| 74012.0| 63557.0|     22884.0|      1721.0| 16044.0|          0.0|          23684.0|\n",
      "|     UA|        1|            795| 26368.0| 24305.0|      5381.0|       653.0|  9480.0|          0.0|           8611.0|\n",
      "|     UA|        7|            645| 16400.0| 16732.0|      3234.0|       134.0|  5695.0|          0.0|           5320.0|\n",
      "|     WN|        1|           5957|157715.0|175318.0|     39856.0|      4685.0| 14420.0|        542.0|          79090.0|\n",
      "|     WN|        7|           3964| 87663.0| 97560.0|     23436.0|       676.0|  8926.0|        347.0|          40440.0|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sundayMondayDelays = [Carrier: string, DayOfWeek: int ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 8 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// analyze Sunday and Monday flight performance for each carrier, including all delay categories\n",
    "//Delays are in Total Minutes\n",
    "val sundayMondayDelays = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek,\n",
    "    COUNT(*) AS NumberOfFlights,\n",
    "    SUM(ArrDelayMinutes) AS ARRDelay,\n",
    "    SUM(DepDelayMinutes) AS DEPDelay,\n",
    "    SUM(CarrierDelay) AS CarrierDelay,\n",
    "    SUM(WeatherDelay) AS WeatherDelay,\n",
    "    SUM(NASDelay) AS NASDelay, \n",
    "    SUM(SecurityDelay) AS SecurityDelay, \n",
    "    SUM(LateAircraftDelay) AS LateAircraftDelay\n",
    "FROM novOntimeView\n",
    "WHERE DayOfWeek IN (1, 7) AND ArrDelayMinutes > 0\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "sundayMondayDelays.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|Carrier|DayOfWeek|NumberOfFlights|ARRDelay|DEPDelay|CarrierDelay|WeatherDelay|LateAircraftDelay|NASDelay|SecurityDelay|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|     AA|        1|           2331|   25.77|   22.26|       19.68|        1.48|            13.44|    16.4|          0.0|\n",
      "|     AA|        7|           1485|   23.81|   23.12|       19.49|        0.48|             13.9|   13.86|         0.02|\n",
      "|     AS|        1|            521|   31.48|   22.29|       10.28|        8.87|            15.56|   26.58|          0.0|\n",
      "|     AS|        7|            344|   24.18|   17.71|       12.87|        0.08|            15.99|   17.59|          0.0|\n",
      "|     B6|        1|            998|   30.72|   27.73|       19.41|         0.0|            16.13|   13.53|         0.09|\n",
      "|     B6|        7|            653|   29.26|   27.03|       23.01|        0.02|            17.98|   10.62|         0.19|\n",
      "|     DL|        1|           3862|   27.47|   23.34|       14.56|        0.67|            17.63|   14.33|          0.0|\n",
      "|     DL|        7|           2774|   26.68|   22.91|       17.34|         1.3|            17.94|   12.15|          0.0|\n",
      "|     UA|        1|            795|   33.17|   30.57|       12.57|        1.53|            20.12|   22.15|          0.0|\n",
      "|     UA|        7|            645|   25.43|   25.94|        9.83|        0.41|            16.17|   17.31|          0.0|\n",
      "|     WN|        1|           5957|   26.48|   29.43|       13.26|        1.56|            26.31|     4.8|         0.18|\n",
      "|     WN|        7|           3964|   22.11|   24.61|       12.75|        0.37|             22.0|    4.86|         0.19|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sundayMondayDelaysAverageRounded = [Carrier: string, DayOfWeek: int ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 8 more fields]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// analyze Sunday and Monday flight performance for each carrier, focusing on average delays per flight\n",
    "val sundayMondayDelaysAverageRounded = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek,\n",
    "    COUNT(*) AS NumberOfFlights,\n",
    "    ROUND(AVG(ArrDelayMinutes), 2) AS ARRDelay,\n",
    "    ROUND(AVG(DepDelayMinutes), 2) AS DEPDelay,\n",
    "    ROUND(AVG(CarrierDelay), 2) AS CarrierDelay,\n",
    "    ROUND(AVG(WeatherDelay), 2) AS WeatherDelay,\n",
    "    ROUND(AVG(LateAircraftDelay), 2) AS LateAircraftDelay,\n",
    "    ROUND(AVG(NASDelay), 2) AS NASDelay,\n",
    "    ROUND(AVG(SecurityDelay), 2) AS SecurityDelay\n",
    "FROM novOntimeView\n",
    "WHERE DayOfWeek IN (1, 7) AND ArrDelayMinutes > 0\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "// Show the results\n",
    "sundayMondayDelaysAverageRounded.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+------------+------------+------------+-----------------+--------+-------------+\n",
      "|Carrier|DayOfWeek|NumberOfFlights|ArrivalDelay|CarrierDelay|WeatherDelay|LateAircraftDelay|NASDelay|SecurityDelay|\n",
      "+-------+---------+---------------+------------+------------+------------+-----------------+--------+-------------+\n",
      "|     AA|        1|           2331|       25.77|        8.56|        0.65|             5.85|    7.14|          0.0|\n",
      "|     AA|        7|           1485|       23.81|        8.28|         0.2|             5.91|    5.89|         0.01|\n",
      "|     AS|        1|            521|       31.48|        4.76|         4.1|              7.2|   12.29|          0.0|\n",
      "|     AS|        7|            344|       24.18|        5.65|        0.03|             7.02|    7.72|          0.0|\n",
      "|     B6|        1|            998|       30.72|       10.97|         0.0|             9.12|    7.65|         0.05|\n",
      "|     B6|        7|            653|       29.26|       11.59|        0.01|             9.06|    5.35|          0.1|\n",
      "|     DL|        1|           3862|       27.47|         7.5|        0.35|             9.08|    7.38|          0.0|\n",
      "|     DL|        7|           2774|       26.68|        8.25|        0.62|             8.54|    5.78|          0.0|\n",
      "|     UA|        1|            795|       33.17|        6.77|        0.82|            10.83|   11.92|          0.0|\n",
      "|     UA|        7|            645|       25.43|        5.01|        0.21|             8.25|    8.83|          0.0|\n",
      "|     WN|        1|           5957|       26.48|        6.69|        0.79|            13.28|    2.42|         0.09|\n",
      "|     WN|        7|           3964|       22.11|        5.91|        0.17|             10.2|    2.25|         0.09|\n",
      "+-------+---------+---------------+------------+------------+------------+-----------------+--------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sundayMondayDelaysAverageRounded = [Carrier: string, DayOfWeek: int ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 7 more fields]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sundayMondayDelaysAverageRounded = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek,\n",
    "    COUNT(*) AS NumberOfFlights,\n",
    "    ROUND(SUM(COALESCE(ArrDelayMinutes, 0)) / COUNT(*), 2) AS ArrivalDelay,\n",
    "    ROUND(SUM(COALESCE(CarrierDelay, 0)) / COUNT(*), 2) AS CarrierDelay,\n",
    "    ROUND(SUM(COALESCE(WeatherDelay, 0)) / COUNT(*), 2) AS WeatherDelay,\n",
    "    ROUND(SUM(COALESCE(LateAircraftDelay, 0)) / COUNT(*), 2) AS LateAircraftDelay,\n",
    "    ROUND(SUM(COALESCE(NASDelay, 0)) / COUNT(*), 2) AS NASDelay,\n",
    "    ROUND(SUM(COALESCE(SecurityDelay, 0)) / COUNT(*), 2) AS SecurityDelay\n",
    "FROM novOntimeView\n",
    "WHERE DayOfWeek IN (1, 7) AND ArrDelayMinutes > 0\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "sundayMondayDelaysAverageRounded.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|Carrier|DayOfWeek|NumberOfFlights|ARRDelay|DEPDelay|CarrierDelay|WeatherDelay|LateAircraftDelay|NASDelay|SecurityDelay|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|     AA|        1|           2331|   25.77|   22.26|        8.56|        0.65|             5.85|    7.14|          0.0|\n",
      "|     AA|        7|           1485|   23.81|   23.12|        8.28|         0.2|             5.91|    5.89|         0.01|\n",
      "|     AS|        1|            521|   31.48|   22.29|        4.76|         4.1|              7.2|   12.29|          0.0|\n",
      "|     AS|        7|            344|   24.18|   17.71|        5.65|        0.03|             7.02|    7.72|          0.0|\n",
      "|     B6|        1|            998|   30.72|   27.73|       10.97|         0.0|             9.12|    7.65|         0.05|\n",
      "|     B6|        7|            653|   29.26|   27.03|       11.59|        0.01|             9.06|    5.35|          0.1|\n",
      "|     DL|        1|           3862|   27.47|   23.34|         7.5|        0.35|             9.08|    7.38|          0.0|\n",
      "|     DL|        7|           2774|   26.68|   22.91|        8.25|        0.62|             8.54|    5.78|          0.0|\n",
      "|     UA|        1|            795|   33.17|   30.57|        6.77|        0.82|            10.83|   11.92|          0.0|\n",
      "|     UA|        7|            645|   25.43|   25.94|        5.01|        0.21|             8.25|    8.83|          0.0|\n",
      "|     WN|        1|           5957|   26.48|   29.43|        6.69|        0.79|            13.28|    2.42|         0.09|\n",
      "|     WN|        7|           3964|   22.11|   24.61|        5.91|        0.17|             10.2|    2.25|         0.09|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sundayMondayDelaysAverageRounded = [Carrier: string, DayOfWeek: int ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 8 more fields]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sundayMondayDelaysAverageRounded = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek,\n",
    "    COUNT(*) AS NumberOfFlights,\n",
    "    ROUND(SUM(COALESCE(ArrDelayMinutes, 0)) / COUNT(*), 2) AS ARRDelay,\n",
    "    ROUND(SUM(COALESCE(DepDelayMinutes, 0)) / COUNT(*), 2) AS DEPDelay, -- Added average departure delay\n",
    "    ROUND(SUM(COALESCE(CarrierDelay, 0)) / COUNT(*), 2) AS CarrierDelay,\n",
    "    ROUND(SUM(COALESCE(WeatherDelay, 0)) / COUNT(*), 2) AS WeatherDelay,\n",
    "    ROUND(SUM(COALESCE(LateAircraftDelay, 0)) / COUNT(*), 2) AS LateAircraftDelay,\n",
    "    ROUND(SUM(COALESCE(NASDelay, 0)) / COUNT(*), 2) AS NASDelay,\n",
    "    ROUND(SUM(COALESCE(SecurityDelay, 0)) / COUNT(*), 2) AS SecurityDelay\n",
    "FROM novOntimeView\n",
    "WHERE DayOfWeek IN (1, 7) AND ArrDelayMinutes > 0\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY Carrier, DayOfWeek\n",
    "\"\"\")\n",
    "\n",
    "sundayMondayDelaysAverageRounded.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|Carrier|DayOfWeek|NumberOfFlights|ARRDelay|DEPDelay|CarrierDelay|WeatherDelay|LateAircraftDelay|NASDelay|SecurityDelay|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "|     UA|        1|            795|   33.17|   30.57|        6.77|        0.82|            10.83|   11.92|          0.0|\n",
      "|     AS|        1|            521|   31.48|   22.29|        4.76|         4.1|              7.2|   12.29|          0.0|\n",
      "|     B6|        1|            998|   30.72|   27.73|       10.97|         0.0|             9.12|    7.65|         0.05|\n",
      "|     B6|        7|            653|   29.26|   27.03|       11.59|        0.01|             9.06|    5.35|          0.1|\n",
      "|     DL|        1|           3862|   27.47|   23.34|         7.5|        0.35|             9.08|    7.38|          0.0|\n",
      "|     DL|        7|           2774|   26.68|   22.91|        8.25|        0.62|             8.54|    5.78|          0.0|\n",
      "|     WN|        1|           5957|   26.48|   29.43|        6.69|        0.79|            13.28|    2.42|         0.09|\n",
      "|     AA|        1|           2331|   25.77|   22.26|        8.56|        0.65|             5.85|    7.14|          0.0|\n",
      "|     UA|        7|            645|   25.43|   25.94|        5.01|        0.21|             8.25|    8.83|          0.0|\n",
      "|     AS|        7|            344|   24.18|   17.71|        5.65|        0.03|             7.02|    7.72|          0.0|\n",
      "|     AA|        7|           1485|   23.81|   23.12|        8.28|         0.2|             5.91|    5.89|         0.01|\n",
      "|     WN|        7|           3964|   22.11|   24.61|        5.91|        0.17|             10.2|    2.25|         0.09|\n",
      "+-------+---------+---------------+--------+--------+------------+------------+-----------------+--------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sundayMondayDelaysAverageRounded = [Carrier: string, DayOfWeek: int ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Carrier: string, DayOfWeek: int ... 8 more fields]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sundayMondayDelaysAverageRounded = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    Carrier, \n",
    "    DayOfWeek,\n",
    "    COUNT(*) AS NumberOfFlights,\n",
    "    ROUND(SUM(COALESCE(ArrDelayMinutes, 0)) / COUNT(*), 2) AS ARRDelay,\n",
    "    ROUND(SUM(COALESCE(DepDelayMinutes, 0)) / COUNT(*), 2) AS DEPDelay, -- Added average departure delay\n",
    "    ROUND(SUM(COALESCE(CarrierDelay, 0)) / COUNT(*), 2) AS CarrierDelay,\n",
    "    ROUND(SUM(COALESCE(WeatherDelay, 0)) / COUNT(*), 2) AS WeatherDelay,\n",
    "    ROUND(SUM(COALESCE(LateAircraftDelay, 0)) / COUNT(*), 2) AS LateAircraftDelay,\n",
    "    ROUND(SUM(COALESCE(NASDelay, 0)) / COUNT(*), 2) AS NASDelay,\n",
    "    ROUND(SUM(COALESCE(SecurityDelay, 0)) / COUNT(*), 2) AS SecurityDelay\n",
    "FROM novOntimeView\n",
    "WHERE DayOfWeek IN (1, 7) AND ArrDelayMinutes > 0\n",
    "GROUP BY Carrier, DayOfWeek\n",
    "ORDER BY ARRDelay DESC  -- Adjusted for sorting by highest average arrival delay\n",
    "\"\"\")\n",
    "\n",
    "sundayMondayDelaysAverageRounded.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Overall Patterns Based on Average Arrival Delays:\n",
    "\n",
    "#### - Higher Traffic, Lower Delays: It seems that the number of flights may inversely correlate with delays. This could suggest that carriers with more flights have more resources and capacity to manage and mitigate delays.\n",
    "\n",
    "#### - Day of the Week Differences: The data suggests that Monday is more prone to delays than Sunday. This could be due to a variety of factors, including increased air traffic, the beginning of the work week causing a surge in travel, or operational resets from the weekend.\n",
    "\n",
    "####  - Carrier-Specific Delays: Certain carriers show a pattern of high delays in specific categories, which may reflect operational challenges unique to each carrier.\n",
    "\n",
    "## Factors Influencing Delays:\n",
    "\n",
    "#### 1. Volume of Flights: WN's higher total minutes of delay correlates with its higher volume of flights. More flights can lead to more total delayed minutes even if the average delay per flight is not the highest.\n",
    "\n",
    "#### 2. Operational Efficiency: The size of the airline and the efficiency of its operations could be a contributing factor. carriers with more flights like WN have complex operations which, when disrupted, can lead to higher late aircraft delays.\n",
    "\n",
    "#### 3. Carrier-Specific Issues: High carrier delays for B6, DL, and AA might indicate issues related to the airlines' own operations, such as maintenance or crew management.\n",
    "\n",
    "#### 4. Weather and Environmental Factors: AS's high weather delays on Monday suggest environmental factors that might be specific to the routes they operate on that day or adverse weather conditions.\n",
    "\n",
    "#### 5. Scheduling Practices: High late aircraft delays, particularly for UA and WN, might indicate tight scheduling and quick turnarounds, which can compound delays.\n",
    "\n",
    "#### 6. Infrastructure and Traffic Control: High NAS delays for UA and AS on Monday could reflect air traffic control issues, airport congestion, or infrastructure limitations at specific airports.\n",
    "\n",
    "#### 7. Minimal Security Delays: Since security delays are negligible across carriers, they do not significantly contribute to overall delay patterns.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
